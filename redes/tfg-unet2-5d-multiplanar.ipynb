{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12259863,"sourceType":"datasetVersion","datasetId":7725477},{"sourceId":12261703,"sourceType":"datasetVersion","datasetId":7726679}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# UNet 2.5D - Entrenamiento y Evaluaci√≥n por Planos (Axial, Coronal, Sagital)\n\nimport os\nimport torch\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nfrom torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\nfrom torchvision import transforms\nimport torch.nn as nn\nfrom copy import deepcopy\nimport pandas as pd\n\n# ==========  Dispositivo ==========\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Usando dispositivo:\", device)\n\n# ========== Modelo ==========\nclass DoubleConv2D(nn.Module):\n    def __init__(self, in_ch, out_ch, dropout_prob=0.1):\n        super().__init__()\n        self.conv = nn.Sequential(\n            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n            nn.BatchNorm2d(out_ch),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n            nn.BatchNorm2d(out_ch),\n            nn.ReLU(inplace=True),\n            nn.Dropout2d(p=dropout_prob)\n        )\n\n    def forward(self, x): return self.conv(x)\n\nclass UNet2_5D(nn.Module):\n    def __init__(self, in_channels=3, out_channels=1, base_filters=64, dropout_prob=0.1):\n        super().__init__()\n        self.enc1 = DoubleConv2D(in_channels, base_filters, dropout_prob)\n        self.enc2 = DoubleConv2D(base_filters, base_filters*2, dropout_prob)\n        self.enc3 = DoubleConv2D(base_filters*2, base_filters*4, dropout_prob)\n        self.pool = nn.MaxPool2d(2)\n\n        self.bottom = DoubleConv2D(base_filters*4, base_filters*8, dropout_prob)\n\n        self.up2 = nn.ConvTranspose2d(base_filters*8, base_filters*4, 2, stride=2)\n        self.dec2 = DoubleConv2D(base_filters*8, base_filters*4, dropout_prob)\n\n        self.up1 = nn.ConvTranspose2d(base_filters*4, base_filters*2, 2, stride=2)\n        self.dec1 = DoubleConv2D(base_filters*4, base_filters*2, dropout_prob)\n\n        self.up0 = nn.ConvTranspose2d(base_filters*2, base_filters, 2, stride=2)\n        self.dec0 = DoubleConv2D(base_filters*2, base_filters, dropout_prob)\n\n        self.out_conv = nn.Conv2d(base_filters, out_channels, 1)\n\n    def forward(self, x):\n        e1 = self.enc1(x)\n        e2 = self.enc2(self.pool(e1))\n        e3 = self.enc3(self.pool(e2))\n        b = self.bottom(self.pool(e3))\n        d2 = self.up2(b)\n        d2 = torch.cat([d2, e3], dim=1)\n        d2 = self.dec2(d2)\n        d1 = self.up1(d2)\n        d1 = torch.cat([d1, e2], dim=1)\n        d1 = self.dec1(d1)\n        d0 = self.up0(d1)\n        d0 = torch.cat([d0, e1], dim=1)\n        d0 = self.dec0(d0)\n        return torch.sigmoid(self.out_conv(d0))\n\n# ========== Dataset ==========\nclass MyoSegDataset25D(Dataset):\n    def __init__(self, image_root, mask_root, plane=\"axial\"):\n        self.samples = []\n        self.weights = []\n\n        for patient_id in sorted(os.listdir(image_root)):\n            img_dir = os.path.join(image_root, patient_id, plane)\n            mask_dir = os.path.join(mask_root, patient_id, plane)\n            if not os.path.isdir(img_dir) or not os.path.isdir(mask_dir):\n                continue\n\n            filenames = sorted(os.listdir(img_dir))\n            for i in range(1, len(filenames) - 1):\n                triplet = [filenames[i - 1], filenames[i], filenames[i + 1]]\n                img_paths = [os.path.join(img_dir, f) for f in triplet]\n                mask_path = os.path.join(mask_dir, filenames[i])\n\n                if all(os.path.exists(p) for p in img_paths) and os.path.exists(mask_path):\n                    self.samples.append((img_paths, mask_path))\n                    mask = np.array(Image.open(mask_path).convert(\"L\")) > 0\n                    pct_foreground = mask.sum() / mask.size\n                    weight = 1.0 + 10.0 * pct_foreground\n                    self.weights.append(weight)\n\n    def __len__(self): return len(self.samples)\n\n    def __getitem__(self, idx):\n        img_paths, mask_path = self.samples[idx]\n        imgs = [transforms.ToTensor()(Image.open(p).convert(\"L\")) for p in img_paths]\n        image_tensor = torch.cat(imgs, dim=0)\n        mask_tensor = (transforms.ToTensor()(Image.open(mask_path).convert(\"L\")) > 0).float()\n        return image_tensor, mask_tensor\n\n# ========== M√©tricas ==========\ndef dice_loss(pred, target, smooth=1.):\n    intersection = (pred * target).sum()\n    return 1 - ((2. * intersection + smooth) / (pred.sum() + target.sum() + smooth))\n\ndef dice_coef(pred, target, smooth=1.): return ((2. * (pred * target).sum() + smooth) / (pred.sum() + target.sum() + smooth)).item()\ndef iou_score(pred, target, smooth=1.): return (((pred * target).sum() + smooth) / (pred.sum() + target.sum() - (pred * target).sum() + smooth)).item()\ndef precision_score(pred, target, smooth=1.): return (((pred * target).sum() + smooth) / ((pred * target).sum() + (pred * (1 - target)).sum() + smooth)).item()\ndef recall_score(pred, target, smooth=1.): return (((pred * target).sum() + smooth) / ((pred * target).sum() + ((1 - pred) * target).sum() + smooth)).item()\ndef f1_score(pred, target, smooth=1.): return (2 * precision_score(pred, target, smooth) * recall_score(pred, target, smooth)) / (precision_score(pred, target, smooth) + recall_score(pred, target, smooth) + 1e-8)\n\n# ========== Entrenamiento por plano ==========\nDATA_DIR = \"/kaggle/input/datsaset-total/New_UNet2.5D\"\nimage_train = f\"{DATA_DIR}/img_2D/img_train\"\nmask_train  = f\"{DATA_DIR}/mask_2D/mask_train\"\nOUTPUT_DIR = \"/kaggle/working\"\n\nPLANES = [\"axial\", \"coronal\", \"sagital\"]\nEPOCHS = 30\nBATCH_SIZE = 4\nTHRESHOLD_METRIC = 0.5\nPATIENCE = 4\nTOLERANCE = 0.01\n\nfor plane in PLANES:\n    print(f\"\\n================== üß¨ ENTRENANDO PLANO: {plane.upper()} ==================\\n\")\n    dataset = MyoSegDataset25D(image_train, mask_train, plane=plane)\n    sampler = WeightedRandomSampler(dataset.weights, len(dataset.weights), replacement=True)\n    train_loader = DataLoader(dataset, batch_size=BATCH_SIZE, sampler=sampler)\n\n    model = UNet2_5D().to(device)\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n\n    best_loss = float(\"inf\")\n    best_model = None\n    epochs_without_improvement = 0\n\n    for epoch in range(EPOCHS):\n        model.train()\n        total_loss = 0\n\n        for img, mask in train_loader:\n            img, mask = img.to(device), mask.to(device)\n            pred = model(img)\n            bce = nn.BCELoss()(pred, mask)\n            loss = 0.5 * dice_loss(pred, mask) + 0.5 * bce\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item()\n\n        avg_loss = total_loss / len(train_loader)\n        print(f\"üìâ Epoch {epoch} | Loss: {avg_loss:.4f}\")\n        \n        # Evaluar m√©tricas en modo eval\n        model.eval()\n        with torch.no_grad():\n            dice_vals, iou_vals, prec_vals, recall_vals, f1_vals = [], [], [], [], []\n            for img, mask in train_loader:\n                img, mask = img.to(device), mask.to(device)\n                pred = model(img)\n                pred_bin = (pred > THRESHOLD_METRIC).float()\n                dice_vals.append(dice_coef(pred_bin, mask))\n                iou_vals.append(iou_score(pred_bin, mask))\n                prec_vals.append(precision_score(pred_bin, mask))\n                recall_vals.append(recall_score(pred_bin, mask))\n                f1_vals.append(f1_score(pred_bin, mask))\n        \n            avg_dice = np.mean(dice_vals)\n            avg_iou = np.mean(iou_vals)\n            avg_prec = np.mean(prec_vals)\n            avg_recall = np.mean(recall_vals)\n            avg_f1 = np.mean(f1_vals)\n        \n            print(f\" M√©tricas | Dice: {avg_dice:.4f} | IoU: {avg_iou:.4f} | Prec: {avg_prec:.4f} | Recall: {avg_recall:.4f} | F1: {avg_f1:.4f}\")\n\n\n        model.eval()\n        with torch.no_grad():\n            idx = np.random.randint(len(dataset))\n            sample_img, sample_mask = dataset[idx]\n            input_tensor = sample_img.unsqueeze(0).to(device)\n            output = model(input_tensor)\n            pred_mask = (output > THRESHOLD_METRIC).float()\n\n            fig, axs = plt.subplots(1, 3, figsize=(12, 4))\n            axs[0].imshow(sample_img[1].cpu().numpy(), cmap=\"gray\")\n            axs[0].set_title(f\"{plane} - Imagen central\")\n            axs[1].imshow(sample_mask.squeeze().cpu().numpy(), cmap=\"gray\")\n            axs[1].set_title(\"M√°scara real\")\n            axs[2].imshow(pred_mask.squeeze().cpu().numpy(), cmap=\"gray\")\n            axs[2].set_title(\"Predicci√≥n\")\n            for ax in axs: ax.axis(\"off\")\n            plt.tight_layout()\n            plt.show()\n\n        if avg_loss < best_loss - TOLERANCE:\n            best_loss = avg_loss\n            best_model = deepcopy(model.state_dict())\n            epochs_without_improvement = 0\n            print(\" Mejor modelo actualizado.\")\n        else:\n            epochs_without_improvement += 1\n            print(f\"‚è≥ Sin mejora ({epochs_without_improvement}/{PATIENCE})\")\n            if epochs_without_improvement >= PATIENCE:\n                print(\" Early stopping activado.\")\n                break\n\n    if best_model:\n        torch.save(best_model, os.path.join(OUTPUT_DIR, f\"unet2_5d_{plane}.pth\"))\n        print(f\" Modelo guardado: unet2_5d_{plane}.pth\")\n    else:\n        print(f\" No se guard√≥ ning√∫n modelo para {plane.upper()} (no hubo mejora)\")\n\n# ========== Evaluaci√≥n y comparativa ==========\nprint(\"\\n EVALUACI√ìN DE LOS TRES PLANOS\\n\")\nresults = []\n\nfor plane in PLANES:\n    model_path = os.path.join(OUTPUT_DIR, f\"unet2_5d_{plane}.pth\")\n    print(f\"\\n Evaluando modelo para plano: {plane.upper()}\")\n    if not os.path.exists(model_path):\n        print(f\" Modelo no encontrado para plano {plane.upper()} ‚Äî saltando evaluaci√≥n.\")\n        continue\n\n    dataset = MyoSegDataset25D(image_root=image_train, mask_root=mask_train, plane=plane)\n    loader = DataLoader(dataset, batch_size=1, shuffle=False)\n\n    model = UNet2_5D().to(device)\n    model.load_state_dict(torch.load(model_path, map_location=device))\n    model.eval()\n\n    dice_list, iou_list, prec_list, recall_list, f1_list = [], [], [], [], []\n\n    with torch.no_grad():\n        for img, mask in loader:\n            img, mask = img.to(device), mask.to(device)\n            output = model(img)\n            pred_bin = (output > THRESHOLD_METRIC).float()\n            dice_list.append(dice_coef(pred_bin, mask))\n            iou_list.append(iou_score(pred_bin, mask))\n            prec_list.append(precision_score(pred_bin, mask))\n            recall_list.append(recall_score(pred_bin, mask))\n            f1_list.append(f1_score(pred_bin, mask))\n\n    avg_dice = np.mean(dice_list)\n    avg_iou = np.mean(iou_list)\n    avg_prec = np.mean(prec_list)\n    avg_recall = np.mean(recall_list)\n    avg_f1 = np.mean(f1_list)\n\n    results.append({\n        \"Plano\": plane,\n        \"Dice\": avg_dice,\n        \"IoU\": avg_iou,\n        \"Precisi√≥n\": avg_prec,\n        \"Recall\": avg_recall,\n        \"F1\": avg_f1\n    })\n\n    print(f\" Dice: {avg_dice:.4f} | IoU: {avg_iou:.4f} | Precisi√≥n: {avg_prec:.4f} | Recall: {avg_recall:.4f} | F1: {avg_f1:.4f}\")\n\n    idx = np.random.randint(len(dataset))\n    sample_img, sample_mask = dataset[idx]\n    input_tensor = sample_img.unsqueeze(0).to(device)\n    output = model(input_tensor)\n    pred_mask = (output > THRESHOLD_METRIC).float()\n\n    fig, axs = plt.subplots(1, 3, figsize=(12, 4))\n    axs[0].imshow(sample_img[1].cpu().numpy(), cmap=\"gray\")\n    axs[0].set_title(f\"{plane} - Imagen central\")\n    axs[1].imshow(sample_mask.squeeze().cpu().numpy(), cmap=\"gray\")\n    axs[1].set_title(\"M√°scara real\")\n    axs[2].imshow(pred_mask.squeeze().cpu().numpy(), cmap=\"gray\")\n    axs[2].set_title(\"Predicci√≥n\")\n    for ax in axs: ax.axis(\"off\")\n    plt.tight_layout()\n    plt.show()\n\nif results:\n    df = pd.DataFrame(results)\n    print(\"\\n Comparativa de m√©tricas por plano:\\n\")\n    print(df.set_index(\"Plano\").round(4))\n    df.to_csv(os.path.join(OUTPUT_DIR, \"metricas_comparativas_planes.csv\"), index=False)\n    print(f\"\\n Resultados guardados en: {os.path.join(OUTPUT_DIR, 'metricas_comparativas_planes.csv')}\")\nelse:\n    print(\"\\n No se ha evaluado ning√∫n modelo. Aseg√∫rate de haber completado el entrenamiento antes.\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-23T17:55:44.898421Z","iopub.execute_input":"2025-06-23T17:55:44.898741Z","iopub.status.idle":"2025-06-23T21:51:43.395228Z","shell.execute_reply.started":"2025-06-23T17:55:44.898716Z","shell.execute_reply":"2025-06-23T21:51:43.394524Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#INFERENCIA SOBRE EL TRAIN:\nimport os\nimport torch\nimport numpy as np\nfrom PIL import Image\nfrom torchvision import transforms\nfrom torch.utils.data import Dataset, DataLoader\nfrom tqdm import tqdm\n\n# ========= Dataset ==========\nclass MyoSegDataset25D(Dataset):\n    def __init__(self, image_root, mask_root, plane=\"axial\"):\n        self.samples = []\n        self.patients = []\n\n        for patient_id in sorted(os.listdir(image_root)):\n            img_dir = os.path.join(image_root, patient_id, plane)\n            mask_dir = os.path.join(mask_root, patient_id, plane)\n            if not os.path.isdir(img_dir) or not os.path.isdir(mask_dir):\n                continue\n\n            filenames = sorted(os.listdir(img_dir))\n            for i in range(1, len(filenames) - 1):\n                triplet = [filenames[i - 1], filenames[i], filenames[i + 1]]\n                img_paths = [os.path.join(img_dir, f) for f in triplet]\n                mask_path = os.path.join(mask_dir, filenames[i])\n\n                if all(os.path.exists(p) for p in img_paths) and os.path.exists(mask_path):\n                    self.samples.append((img_paths, mask_path))\n                    self.patients.append(patient_id)\n\n    def __len__(self): return len(self.samples)\n\n    def __getitem__(self, idx):\n        img_paths, mask_path = self.samples[idx]\n        imgs = [transforms.ToTensor()(Image.open(p).convert(\"L\")) for p in img_paths]\n        image_tensor = torch.cat(imgs, dim=0)\n        filename = os.path.basename(mask_path)\n        patient = self.patients[idx]\n        return image_tensor, filename, patient\n\n\n# ========= Modelo UNet 2.5D ==========\nclass DoubleConv2D(torch.nn.Module):\n    def __init__(self, in_ch, out_ch, dropout_prob=0.1):\n        super().__init__()\n        self.conv = torch.nn.Sequential(\n            torch.nn.Conv2d(in_ch, out_ch, 3, padding=1),\n            torch.nn.BatchNorm2d(out_ch),\n            torch.nn.ReLU(inplace=True),\n            torch.nn.Conv2d(out_ch, out_ch, 3, padding=1),\n            torch.nn.BatchNorm2d(out_ch),\n            torch.nn.ReLU(inplace=True),\n            torch.nn.Dropout2d(p=dropout_prob)\n        )\n\n    def forward(self, x): return self.conv(x)\n\nclass UNet2_5D(torch.nn.Module):\n    def __init__(self, in_channels=3, out_channels=1, base_filters=64, dropout_prob=0.1):\n        super().__init__()\n        self.enc1 = DoubleConv2D(in_channels, base_filters, dropout_prob)\n        self.enc2 = DoubleConv2D(base_filters, base_filters*2, dropout_prob)\n        self.enc3 = DoubleConv2D(base_filters*2, base_filters*4, dropout_prob)\n        self.pool = torch.nn.MaxPool2d(2)\n        self.bottom = DoubleConv2D(base_filters*4, base_filters*8, dropout_prob)\n        self.up2 = torch.nn.ConvTranspose2d(base_filters*8, base_filters*4, 2, stride=2)\n        self.dec2 = DoubleConv2D(base_filters*8, base_filters*4, dropout_prob)\n        self.up1 = torch.nn.ConvTranspose2d(base_filters*4, base_filters*2, 2, stride=2)\n        self.dec1 = DoubleConv2D(base_filters*4, base_filters*2, dropout_prob)\n        self.up0 = torch.nn.ConvTranspose2d(base_filters*2, base_filters, 2, stride=2)\n        self.dec0 = DoubleConv2D(base_filters*2, base_filters, dropout_prob)\n        self.out_conv = torch.nn.Conv2d(base_filters, out_channels, 1)\n\n    def forward(self, x):\n        e1 = self.enc1(x)\n        e2 = self.enc2(self.pool(e1))\n        e3 = self.enc3(self.pool(e2))\n        b = self.bottom(self.pool(e3))\n        d2 = self.dec2(torch.cat([self.up2(b), e3], dim=1))\n        d1 = self.dec1(torch.cat([self.up1(d2), e2], dim=1))\n        d0 = self.dec0(torch.cat([self.up0(d1), e1], dim=1))\n        return torch.sigmoid(self.out_conv(d0))\n\n\n# ========= Inferencia por plano ==========\ndef infer_and_save(plane, model_path, image_root, mask_root, output_dir, threshold=0.5):\n    print(f\"\\nüîç Inferencia del plano: {plane.upper()}\")\n\n    # Cargar dataset\n    dataset = MyoSegDataset25D(image_root, mask_root, plane=plane)\n    loader = DataLoader(dataset, batch_size=1, shuffle=False)\n\n    # Cargar modelo\n    model = UNet2_5D().to(device)\n    model.load_state_dict(torch.load(model_path, map_location=device))\n    model.eval()\n\n    for img, fname, patient in tqdm(loader):\n        img = img.to(device)\n        with torch.no_grad():\n            pred = model(img)\n            pred_mask = (pred > threshold).float().squeeze().cpu().numpy() * 255\n\n        save_path = os.path.join(output_dir, plane, patient[0])\n        os.makedirs(save_path, exist_ok=True)\n        Image.fromarray(pred_mask.astype(np.uint8)).save(os.path.join(save_path, fname[0]))\n\n    print(f\" Predicciones del plano {plane.upper()} guardadas en {os.path.join(output_dir, plane)}\")\n\n\n# ========= Configuraci√≥n ==========\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Usando dispositivo:\", device)\n\nDATASET_DIR = \"/kaggle/input/datsaset-total/New_UNet2.5D\"\nPLANOS_DIR = \"/kaggle/input/planos\"\nOUT_DIR = \"/kaggle/working/predicciones_por_plano\"\n\nimage_root = os.path.join(DATASET_DIR, \"img_2D\", \"img_train\")\nmask_root = os.path.join(DATASET_DIR, \"mask_2D\", \"mask_train\")\n\nplanes = [\"axial\", \"coronal\", \"sagital\"]\nfor plane in planes:\n    model_path = os.path.join(PLANOS_DIR, f\"unet2_5d_{plane}.pth\")\n    infer_and_save(plane, model_path, image_root, mask_root, OUT_DIR)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T17:50:36.016959Z","iopub.execute_input":"2025-06-26T17:50:36.01734Z","iopub.status.idle":"2025-06-26T17:56:23.323145Z","shell.execute_reply.started":"2025-06-26T17:50:36.01732Z","shell.execute_reply":"2025-06-26T17:56:23.322385Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#INFERENCIA SOBRE EL TEST\n\nimport os\nimport torch\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nfrom torchvision import transforms\nfrom torch.utils.data import Dataset, DataLoader\n\n# ========== üíª Dispositivo ==========\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Usando dispositivo:\", device)\n\n# ========== üõ†Ô∏è Modelo (misma UNet2_5D) ==========\nclass DoubleConv2D(torch.nn.Module):\n    def __init__(self, in_ch, out_ch, dropout_prob=0.1):\n        super().__init__()\n        self.conv = torch.nn.Sequential(\n            torch.nn.Conv2d(in_ch, out_ch, 3, padding=1),\n            torch.nn.BatchNorm2d(out_ch),\n            torch.nn.ReLU(inplace=True),\n            torch.nn.Conv2d(out_ch, out_ch, 3, padding=1),\n            torch.nn.BatchNorm2d(out_ch),\n            torch.nn.ReLU(inplace=True),\n            torch.nn.Dropout2d(p=dropout_prob)\n        )\n\n    def forward(self, x): return self.conv(x)\n\nclass UNet2_5D(torch.nn.Module):\n    def __init__(self, in_channels=3, out_channels=1, base_filters=64, dropout_prob=0.1):\n        super().__init__()\n        self.enc1 = DoubleConv2D(in_channels, base_filters, dropout_prob)\n        self.enc2 = DoubleConv2D(base_filters, base_filters*2, dropout_prob)\n        self.enc3 = DoubleConv2D(base_filters*2, base_filters*4, dropout_prob)\n        self.pool = torch.nn.MaxPool2d(2)\n        self.bottom = DoubleConv2D(base_filters*4, base_filters*8, dropout_prob)\n        self.up2 = torch.nn.ConvTranspose2d(base_filters*8, base_filters*4, 2, stride=2)\n        self.dec2 = DoubleConv2D(base_filters*8, base_filters*4, dropout_prob)\n        self.up1 = torch.nn.ConvTranspose2d(base_filters*4, base_filters*2, 2, stride=2)\n        self.dec1 = DoubleConv2D(base_filters*4, base_filters*2, dropout_prob)\n        self.up0 = torch.nn.ConvTranspose2d(base_filters*2, base_filters, 2, stride=2)\n        self.dec0 = DoubleConv2D(base_filters*2, base_filters, dropout_prob)\n        self.out_conv = torch.nn.Conv2d(base_filters, out_channels, 1)\n\n    def forward(self, x):\n        e1 = self.enc1(x)\n        e2 = self.enc2(self.pool(e1))\n        e3 = self.enc3(self.pool(e2))\n        b = self.bottom(self.pool(e3))\n        d2 = self.up2(b)\n        d2 = torch.cat([d2, e3], dim=1)\n        d2 = self.dec2(d2)\n        d1 = self.up1(d2)\n        d1 = torch.cat([d1, e2], dim=1)\n        d1 = self.dec1(d1)\n        d0 = self.up0(d1)\n        d0 = torch.cat([d0, e1], dim=1)\n        d0 = self.dec0(d0)\n        return torch.sigmoid(self.out_conv(d0))\n\n# ========== üìÇ Dataset solo para im√°genes ==========\nclass MyoSegTestDataset25D(Dataset):\n    def __init__(self, image_root, plane=\"axial\"):\n        self.samples = []\n        for patient_id in sorted(os.listdir(image_root)):\n            img_dir = os.path.join(image_root, patient_id, plane)\n            if not os.path.isdir(img_dir): continue\n            filenames = sorted(os.listdir(img_dir))\n            for i in range(1, len(filenames) - 1):\n                triplet = [filenames[i - 1], filenames[i], filenames[i + 1]]\n                img_paths = [os.path.join(img_dir, f) for f in triplet]\n                if all(os.path.exists(p) for p in img_paths):\n                    self.samples.append(img_paths)\n\n    def __len__(self): return len(self.samples)\n\n    def __getitem__(self, idx):\n        img_paths = self.samples[idx]\n        imgs = [transforms.ToTensor()(Image.open(p).convert(\"L\")) for p in img_paths]\n        image_tensor = torch.cat(imgs, dim=0)\n        return image_tensor\n\n# ========== üöÄ Inferencia ==========\nDATA_DIR = \"/kaggle/input/datsaset-total/New_UNet2.5D\"\nWEIGHTS_DIR = \"/kaggle/input/planos\"\nimage_test = f\"{DATA_DIR}/img_2D/img_test\"\nTHRESHOLD_METRIC = 0.5\nPLANES = [\"axial\", \"coronal\", \"sagital\"]\n\nfrom tqdm import tqdm  # Para barra de progreso si quieres\n\nmask_test = f\"{DATA_DIR}/mask_2D/mask_test\"  # Ruta a las m√°scaras reales de test\n\nprint(\"\\n================== üß™ INFERENCIA Y M√âTRICAS SOBRE TEST ==================\")\nfor plane in PLANES:\n    print(f\"\\nüîç Evaluando plano: {plane.upper()}\")\n    model_path = os.path.join(WEIGHTS_DIR, f\"unet2_5d_{plane}.pth\")\n    if not os.path.exists(model_path):\n        print(f\"‚ö†Ô∏è No se encontr√≥ el modelo para {plane}\")\n        continue\n\n    dataset = MyoSegTestDataset25DWithMasks(image_root=image_test, mask_root=mask_test, plane=plane)\n    if len(dataset) == 0:\n        print(\"‚ö†Ô∏è No hay datos v√°lidos para este plano.\")\n        continue\n\n    loader = DataLoader(dataset, batch_size=1, shuffle=False)\n    model = UNet2_5D().to(device)\n    model.load_state_dict(torch.load(model_path, map_location=device))\n    model.eval()\n\n    dice_list, iou_list, prec_list, recall_list, f1_list = [], [], [], [], []\n\n    with torch.no_grad():\n        for img, mask in tqdm(loader):\n            img, mask = img.to(device), mask.to(device)\n            output = model(img)\n            pred_bin = (output > THRESHOLD_METRIC).float()\n\n            dice_list.append(dice_coef(pred_bin, mask))\n            iou_list.append(iou_score(pred_bin, mask))\n            prec_list.append(precision_score(pred_bin, mask))\n            recall_list.append(recall_score(pred_bin, mask))\n            f1_list.append(f1_score(pred_bin, mask))\n\n    avg_dice = np.mean(dice_list)\n    avg_iou = np.mean(iou_list)\n    avg_prec = np.mean(prec_list)\n    avg_recall = np.mean(recall_list)\n    avg_f1 = np.mean(f1_list)\n\n    print(f\"‚úÖ Resultados para {plane.upper()} ‚Äî Dice: {avg_dice:.4f} | IoU: {avg_iou:.4f} | Precisi√≥n: {avg_prec:.4f} | Recall: {avg_recall:.4f} | F1: {avg_f1:.4f}\")\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import shutil\n\nshutil.make_archive(\"/kaggle/working/predicciones_sin_post\", 'zip', \"/kaggle/working/predicciones_test\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T22:49:07.140129Z","iopub.execute_input":"2025-06-23T22:49:07.140647Z","iopub.status.idle":"2025-06-23T22:49:07.686232Z","shell.execute_reply.started":"2025-06-23T22:49:07.140616Z","shell.execute_reply":"2025-06-23T22:49:07.685616Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Visualizaci√≥n de las predicciones del test\n\nimport os\nimport random\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport numpy as np\n\nIMG_DIR = \"/kaggle/input/datsaset-total/New_UNet2.5D/img_2D/img_test\"\nPRED_DIR = \"/kaggle/working/predicciones_test\"\nPLANOS = [\"axial\", \"coronal\", \"sagital\"]\nNUM_EJEMPLOS = 10\n\n# Recoger ejemplos v√°lidos\nejemplos = []\nfor plano in PLANOS:\n    plano_dir = os.path.join(PRED_DIR, plano)\n    for paciente in os.listdir(plano_dir):\n        pred_path = os.path.join(plano_dir, paciente)\n        img_path = os.path.join(IMG_DIR, paciente, plano)\n        if not os.path.isdir(pred_path) or not os.path.isdir(img_path):\n            continue\n        for fname in os.listdir(pred_path):\n            img_name = fname\n            orig_path = os.path.join(img_path, img_name)\n            pred_path_img = os.path.join(pred_path, fname)\n            if os.path.exists(orig_path):\n                ejemplos.append((plano, paciente, img_name, orig_path, pred_path_img))\n\n# Seleccionar aleatoriamente\nejemplos_mostrar = random.sample(ejemplos, min(NUM_EJEMPLOS, len(ejemplos)))\n\n# Mostrar\nfor plano, paciente, fname, orig_path, pred_path in ejemplos_mostrar:\n    img = np.array(Image.open(orig_path).convert(\"L\"))\n    pred = np.array(Image.open(pred_path).convert(\"L\")) > 0\n\n    # Normalizar imagen a [0, 1] y expandir a RGB\n    img_rgb = np.stack([img] * 3, axis=-1) / 255.0\n\n    # Crear overlay con canal rojo donde hay predicci√≥n\n    overlay = img_rgb.copy()\n    overlay[pred, 0] = 1.0   # rojo\n    overlay[pred, 1] = 0.0   # quitar verde\n    overlay[pred, 2] = 0.0   # quitar azul\n\n    # Opcional: hacer mezcla alfa para transparencia\n    alpha = 0.4\n    overlay = (1 - alpha) * img_rgb + alpha * overlay\n\n    fig, axs = plt.subplots(1, 3, figsize=(12, 4))\n\n    axs[0].imshow(img, cmap=\"gray\")\n    axs[0].set_title(\"Imagen original\")\n\n    axs[1].imshow(pred, cmap=\"gray\")\n    axs[1].set_title(\"M√°scara predicha\")\n\n    axs[2].imshow(overlay)\n    axs[2].set_title(\"Overlay\")\n\n    for ax in axs:\n        ax.axis(\"off\")\n    plt.suptitle(f\"{plano.upper()} | Paciente: {paciente} | Archivo: {fname}\", fontsize=10)\n    plt.tight_layout()\n    plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T23:02:23.972703Z","iopub.execute_input":"2025-06-23T23:02:23.973206Z","iopub.status.idle":"2025-06-23T23:02:30.029762Z","shell.execute_reply.started":"2025-06-23T23:02:23.973184Z","shell.execute_reply":"2025-06-23T23:02:30.029037Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Post-procesado de las predicciones del conjunto de test\n\nimport os\nfrom PIL import Image\nimport numpy as np\nfrom tqdm import tqdm\nfrom scipy.ndimage import binary_fill_holes, binary_closing, binary_erosion, binary_dilation\nfrom skimage.morphology import remove_small_objects, disk\nfrom skimage.filters import gaussian\nfrom skimage.io import imsave\nfrom skimage.segmentation import random_walker\nimport shutil\n\n# Rutas\nPRED_DIR = \"predicciones_test\"\nIMG_DIR = \"/kaggle/input/datsaset-total/New_UNet2.5D/img_2D/img_test\"  # ‚ö†Ô∏è Aseg√∫rate de tener las im√°genes originales aqu√≠ (mismo nombre y estructura)\nOUT_DIR = \"predicciones_post_random_walker\"\nPLANOS = [\"axial\", \"coronal\", \"sagital\"]\n\ndef aplicar_random_walker(imagen_gray, mascara_binaria, fondo_dilatado=False):\n    \"\"\"\n    Expande la m√°scara usando Random Walker guiado por la imagen original.\n    \"\"\"\n    # Semillas: 1 donde hay m√°scara, 2 donde se asume fondo\n    seeds = np.zeros_like(mascara_binaria, dtype=np.uint8)\n    seeds[mascara_binaria > 0] = 1\n\n    if fondo_dilatado:\n        fondo = binary_dilation(mascara_binaria == 0, structure=disk(5))\n        seeds[fondo & (seeds == 0)] = 2\n    else:\n        seeds[mascara_binaria == 0] = 2\n\n    # Normalizamos imagen entre 0 y 1\n    imagen_norm = (imagen_gray - imagen_gray.min()) / (imagen_gray.max() - imagen_gray.min() + 1e-8)\n\n    try:\n        labels = random_walker(imagen_norm, seeds, beta=250, mode='bf')\n        resultado = (labels == 1).astype(np.uint8)\n    except:\n        # Si falla (por ejemplo imagen vac√≠a), devolvemos la m√°scara original\n        resultado = mascara_binaria.astype(np.uint8)\n\n    return resultado\n\ndef postprocesar_mascara(mask_binaria, min_area=400, suavizar=True):\n    \"\"\"\n    Limpieza morfol√≥gica cl√°sica de la m√°scara binaria.\n    \"\"\"\n    mask = mask_binaria.astype(bool)\n\n    mask = remove_small_objects(mask, min_size=min_area)\n    mask = binary_fill_holes(mask)\n    mask = binary_closing(mask, structure=disk(8))\n\n    if suavizar:\n        mask = binary_erosion(mask, structure=disk(4))\n        mask = gaussian(mask.astype(float), sigma=2) > 0.5\n\n    return mask.astype(np.uint8)\n\n# Procesamiento general\nfor plano in PLANOS:\n    in_pred_dir = os.path.join(PRED_DIR, plano)\n    out_dir = os.path.join(OUT_DIR, plano)\n    os.makedirs(out_dir, exist_ok=True)\n\n    print(f\"\\nüß† Procesando plano: {plano.upper()}\")\n\n    for paciente in tqdm(os.listdir(in_pred_dir), desc=f\"{plano.upper()}\"):\n        pred_paciente_dir = os.path.join(in_pred_dir, paciente)\n        img_paciente_dir = os.path.join(IMG_DIR, paciente, plano)  # ‚úÖ solo se a√±ade plano aqu√≠\n        out_paciente_dir = os.path.join(out_dir, paciente)\n        os.makedirs(out_paciente_dir, exist_ok=True)\n\n        for fname in os.listdir(pred_paciente_dir):\n            pred_path = os.path.join(pred_paciente_dir, fname)\n            img_path = os.path.join(img_paciente_dir, fname)  # ‚úÖ construida correctamente\n            out_path = os.path.join(out_paciente_dir, fname)\n\n            if not os.path.exists(img_path):\n                print(f\"‚ö†Ô∏è Imagen no encontrada, se omite: {img_path}\")\n                continue\n\n            pred = np.array(Image.open(pred_path).convert(\"L\")) > 0\n            imagen = np.array(Image.open(img_path).convert(\"L\"))\n\n            pred_proc = postprocesar_mascara(pred, min_area=400)\n            pred_final = aplicar_random_walker(imagen, pred_proc, fondo_dilatado=True)\n\n            imsave(out_path, (pred_final * 255).astype(np.uint8))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T01:17:05.595212Z","iopub.execute_input":"2025-06-24T01:17:05.595864Z","iopub.status.idle":"2025-06-24T01:21:32.937137Z","shell.execute_reply.started":"2025-06-24T01:17:05.595841Z","shell.execute_reply":"2025-06-24T01:21:32.936462Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Visualizaci√≥n y comparativa entre las predicciones del test con y sin post-procesado\n\nimport os\nimport random\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport numpy as np\n\n# üìÅ Directorios\nIMG_DIR = \"/kaggle/input/datsaset-total/New_UNet2.5D/img_2D/img_test\"\nPRED_DIR = \"/kaggle/working/predicciones_test\"\nPOST_DIR = \"/kaggle/working/predicciones_post_random_walker\" \nPLANOS = [\"axial\", \"coronal\", \"sagital\"]\nNUM_EJEMPLOS = 10\n\n# üé® Funci√≥n overlay\ndef crear_overlay(img, mask, color=[1.0, 0.0, 0.0], alpha=0.4):\n    img_rgb = np.stack([img]*3, axis=-1) / 255.0\n    overlay = img_rgb.copy()\n    overlay[mask] = color\n    return (1 - alpha) * img_rgb + alpha * overlay\n\n# üîç Buscar ejemplos v√°lidos\nejemplos = []\nfor plano in PLANOS:\n    plano_pred_dir = os.path.join(PRED_DIR, plano)\n    plano_post_dir = os.path.join(POST_DIR, plano)\n\n    for paciente in os.listdir(plano_pred_dir):\n        pred_path = os.path.join(plano_pred_dir, paciente)\n        post_path = os.path.join(plano_post_dir, paciente)\n        img_path = os.path.join(IMG_DIR, paciente, plano)\n\n        if not (os.path.isdir(pred_path) and os.path.isdir(post_path) and os.path.isdir(img_path)):\n            continue\n\n        for fname in os.listdir(pred_path):\n            orig_img = os.path.join(img_path, fname)\n            pred_img = os.path.join(pred_path, fname)\n            post_img = os.path.join(post_path, fname)\n            if os.path.exists(orig_img) and os.path.exists(post_img):\n                ejemplos.append((plano, paciente, fname, orig_img, pred_img, post_img))\n\n# üì¢ Comprobaci√≥n\nif not ejemplos:\n    print(\"‚ö†Ô∏è No se encontraron ejemplos v√°lidos para visualizar.\")\nelse:\n    ejemplos_mostrar = random.sample(ejemplos, min(NUM_EJEMPLOS, len(ejemplos)))\n    print(f\"‚úÖ Visualizando {len(ejemplos_mostrar)} ejemplos...\")\n\n    # üëÅÔ∏è Mostrar\n    for plano, paciente, fname, orig_path, pred_path, post_path in ejemplos_mostrar:\n        img = np.array(Image.open(orig_path).convert(\"L\"))\n        pred = np.array(Image.open(pred_path).convert(\"L\")) > 0\n        post = np.array(Image.open(post_path).convert(\"L\")) > 0\n\n        overlay_pred = crear_overlay(img, pred)\n        overlay_post = crear_overlay(img, post)\n\n        fig, axs = plt.subplots(1, 4, figsize=(16, 4))\n\n        axs[0].imshow(img, cmap=\"gray\")\n        axs[0].set_title(\"Imagen original\")\n\n        axs[1].imshow(overlay_pred)\n        axs[1].set_title(\"Overlay predicci√≥n\")\n\n        axs[2].imshow(post, cmap=\"gray\")\n        axs[2].set_title(\"Postprocesada\")\n\n        axs[3].imshow(overlay_post)\n        axs[3].set_title(\"Overlay postprocesada\")\n\n        for ax in axs:\n            ax.axis(\"off\")\n\n        plt.suptitle(f\"{plano.upper()} | Paciente: {paciente} | Archivo: {fname}\", fontsize=10)\n        plt.tight_layout()\n        plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T01:39:48.685118Z","iopub.execute_input":"2025-06-24T01:39:48.685398Z","iopub.status.idle":"2025-06-24T01:39:55.188631Z","shell.execute_reply.started":"2025-06-24T01:39:48.685376Z","shell.execute_reply":"2025-06-24T01:39:55.187665Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Comprimir en ZIP\nshutil.make_archive(\"predicciones_post_random_walker\", 'zip', OUT_DIR)\nprint(\"\\n‚úÖ Archivo ZIP generado: predicciones_post_random_walker.zip\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T01:40:06.361273Z","iopub.execute_input":"2025-06-24T01:40:06.36152Z","iopub.status.idle":"2025-06-24T01:40:06.834461Z","shell.execute_reply.started":"2025-06-24T01:40:06.361503Z","shell.execute_reply":"2025-06-24T01:40:06.833715Z"}},"outputs":[],"execution_count":null}]}
{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12186134,"sourceType":"datasetVersion","datasetId":7675545},{"sourceId":12285657,"sourceType":"datasetVersion","datasetId":7742667}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#ValidaciÃ³n cruzada\n\nimport os\nimport torch\nimport numpy as np\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom torch.utils.data import Dataset, DataLoader, Subset\nfrom torchvision import transforms\nfrom sklearn.model_selection import LeaveOneGroupOut\nimport torch\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Dispositivo:\", device)\n\n\nclass MyoSegDataset2D(Dataset):\n    def __init__(self, image_root, mask_root):\n        self.image_paths, self.mask_paths, self.patients = [], [], []\n        for patient in sorted(os.listdir(image_root)):\n            img_folder = os.path.join(image_root, patient)\n            mask_folder = os.path.join(mask_root, patient)\n            if not os.path.isdir(mask_folder):\n                print(f\"âš ï¸ Falta mÃ¡scara para {patient}\")\n                continue\n\n            imgs = sorted([f for f in os.listdir(img_folder) if f.endswith('.png')])\n            masks = sorted([f for f in os.listdir(mask_folder) if f.endswith('.png')])\n            for i, m in zip(imgs, masks):\n                self.image_paths.append(os.path.join(img_folder, i))\n                self.mask_paths.append(os.path.join(mask_folder, m))\n                self.patients.append(patient)\n\n        self.transform = transforms.ToTensor()\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        img = Image.open(self.image_paths[idx]).convert(\"L\")\n        mask = Image.open(self.mask_paths[idx]).convert(\"L\")\n        img = self.transform(img)\n        mask = (self.transform(mask) > 0).float()\n        return img, mask, self.image_paths[idx], self.patients[idx]\n\nimport torch.nn as nn\n\nclass DoubleConv2D(nn.Module):\n    def __init__(self, in_ch, out_ch, p=0.1):\n        super().__init__()\n        self.conv = nn.Sequential(\n            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n            nn.BatchNorm2d(out_ch),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n            nn.BatchNorm2d(out_ch),\n            nn.ReLU(inplace=True),\n            nn.Dropout2d(p)\n        )\n\n    def forward(self, x):\n        return self.conv(x)\n\nclass UNet2D(nn.Module):\n    def __init__(self, in_channels=1, out_channels=1, base_filters=64, p=0.1):\n        super().__init__()\n        self.enc1 = DoubleConv2D(in_channels, base_filters, p)\n        self.enc2 = DoubleConv2D(base_filters, base_filters*2, p)\n        self.enc3 = DoubleConv2D(base_filters*2, base_filters*4, p)\n        self.pool = nn.MaxPool2d(2)\n        self.bottom = DoubleConv2D(base_filters*4, base_filters*8, p)\n        self.up2 = nn.ConvTranspose2d(base_filters*8, base_filters*4, 2, stride=2)\n        self.dec2 = DoubleConv2D(base_filters*8, base_filters*4, p)\n        self.up1 = nn.ConvTranspose2d(base_filters*4, base_filters*2, 2, stride=2)\n        self.dec1 = DoubleConv2D(base_filters*4, base_filters*2, p)\n        self.up0 = nn.ConvTranspose2d(base_filters*2, base_filters, 2, stride=2)\n        self.dec0 = DoubleConv2D(base_filters*2, base_filters, p)\n        self.out_conv = nn.Conv2d(base_filters, out_channels, 1)\n\n    def forward(self, x):\n        e1 = self.enc1(x)\n        e2 = self.enc2(self.pool(e1))\n        e3 = self.enc3(self.pool(e2))\n        b = self.bottom(self.pool(e3))\n        d2 = self.dec2(torch.cat([self.up2(b), e3], dim=1))\n        d1 = self.dec1(torch.cat([self.up1(d2), e2], dim=1))\n        d0 = self.dec0(torch.cat([self.up0(d1), e1], dim=1))\n        return torch.sigmoid(self.out_conv(d0))\n\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n\n# === Rutas necesarias ===\nimage_root = \"/kaggle/input/dataset/New-UNet2D/img_2D/img_train\"\nmask_root = \"/kaggle/input/dataset/New-UNet2D/mask_2D/mask_train\"\n\nprint(\"ğŸ“ Contenido de las rutas:\")\nprint(\"image_root:\", image_root)\nprint(\"mask_root:\", mask_root)\nprint(\"Pacientes con imagen:\", os.listdir(image_root))\nprint(\"Pacientes con mÃ¡scara:\", os.listdir(mask_root))\n\n# === Cargar dataset\ndataset = MyoSegDataset2D(image_root, mask_root)\n\n# === Imprimir informaciÃ³n del dataset\nprint(f\"ğŸ“Š Total muestras cargadas: {len(dataset)}\")\nprint(f\"ğŸ‘¥ Pacientes detectados: {set(dataset.patients)}\")\n\n# === Cargar dataset y modelo ===\ndataset = MyoSegDataset2D(image_root, mask_root)\npatient_ids = np.array(dataset.patients)\nlogo = LeaveOneGroupOut()\n\n# Identificar Ã­ndices de train/val para fold 5\nFOLD_ID = 4  # Fold 5 â†’ Ã­ndice 4 (Python index starts at 0)\nsplits = list(logo.split(np.arange(len(dataset)), groups=patient_ids))\ntrain_idx, val_idx = splits[FOLD_ID]\n\n# Crear loader de entrenamiento\ntrain_subset = Subset(dataset, train_idx)\ntrain_loader = DataLoader(train_subset, batch_size=1, shuffle=False)\n\n# Cargar modelo\nmodel = UNet2D().to(device)\nmodel.load_state_dict(torch.load(\"/kaggle/input/best-model/unet2d_best_fold5.pth\"))\nmodel.eval()\n\n# Crear carpeta para guardar predicciones si quieres\nos.makedirs(\"predicciones_train_fold5\", exist_ok=True)\n\n# === Inferencia sobre pacientes de entrenamiento ===\nwith torch.no_grad():\n    for i, (img, mask, path, patient_id) in tqdm(enumerate(train_loader), total=len(train_loader)):\n        img, mask = img.to(device), mask.to(device)\n        pred = model(img)\n        pred_bin = (pred > 0.5).float()\n\n        # VisualizaciÃ³n rÃ¡pida\n        pred_np = pred.squeeze().cpu().numpy()\n        overlay = np.clip(img.squeeze().cpu().numpy() + pred_np, 0, 1)\n\n        fig, axs = plt.subplots(1, 3, figsize=(12, 4))\n        axs[0].imshow(img.squeeze().cpu(), cmap=\"gray\"); axs[0].set_title(\"Imagen\")\n        axs[1].imshow(mask.squeeze().cpu(), cmap=\"gray\"); axs[1].set_title(\"MÃ¡scara GT\")\n        axs[2].imshow(overlay, cmap=\"hot\"); axs[2].set_title(\"PredicciÃ³n\")\n        for ax in axs: ax.axis(\"off\")\n        plt.tight_layout()\n        plt.savefig(f\"predicciones_train_fold5/pred_{i:03d}.png\")\n        plt.close()\n\nfrom torch.utils.data import Subset\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T22:17:11.767603Z","iopub.execute_input":"2025-06-26T22:17:11.767887Z","execution_failed":"2025-06-26T23:28:13.057Z"}},"outputs":[{"name":"stdout","text":"Dispositivo: cuda\nğŸ“ Contenido de las rutas:\nimage_root: /kaggle/input/dataset/New-UNet2D/img_2D/img_train\nmask_root: /kaggle/input/dataset/New-UNet2D/mask_2D/mask_train\nPacientes con imagen: ['2851790', '1297164', '1405347', '1637400', '6554609', '1741355']\nPacientes con mÃ¡scara: ['2851790', '1297164', '1405347', '1637400', '6554609', '1741355']\nğŸ“Š Total muestras cargadas: 8064\nğŸ‘¥ Pacientes detectados: {'1297164', '2851790', '6554609', '1637400', '1405347', '1741355'}\n","output_type":"stream"},{"name":"stderr","text":" 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 3022/6720 [19:25<22:13,  2.77it/s]  ","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"#Predicciones del paciente de validaciÃ³n del fold 5\n\nimport os\nimport torch\nimport numpy as np\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom torch.utils.data import Dataset, DataLoader, Subset\nfrom torchvision import transforms\nfrom sklearn.model_selection import LeaveOneGroupOut\nimport torch\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Dispositivo:\", device)\n\n\n\nclass MyoSegDataset2D(Dataset):\n    def __init__(self, image_root, mask_root):\n        self.image_paths, self.mask_paths, self.patients = [], [], []\n        for patient in sorted(os.listdir(image_root)):\n            img_folder = os.path.join(image_root, patient)\n            mask_folder = os.path.join(mask_root, patient)\n            if not os.path.isdir(mask_folder): continue\n            imgs = sorted([f for f in os.listdir(img_folder) if f.endswith('.png')])\n            masks = sorted([f for f in os.listdir(mask_folder) if f.endswith('.png')])\n            for i, m in zip(imgs, masks):\n                self.image_paths.append(os.path.join(img_folder, i))\n                self.mask_paths.append(os.path.join(mask_folder, m))\n                self.patients.append(patient)\n\n        self.transform = transforms.ToTensor()\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        img = Image.open(self.image_paths[idx]).convert(\"L\")\n        mask = Image.open(self.mask_paths[idx]).convert(\"L\")\n        img = self.transform(img)\n        mask = (self.transform(mask) > 0).float()\n        return img, mask, self.image_paths[idx], self.patients[idx]\n\nimport torch.nn as nn\n\nclass DoubleConv2D(nn.Module):\n    def __init__(self, in_ch, out_ch, p=0.1):\n        super().__init__()\n        self.conv = nn.Sequential(\n            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n            nn.BatchNorm2d(out_ch),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n            nn.BatchNorm2d(out_ch),\n            nn.ReLU(inplace=True),\n            nn.Dropout2d(p)\n        )\n\n    def forward(self, x):\n        return self.conv(x)\n\nclass UNet2D(nn.Module):\n    def __init__(self, in_channels=1, out_channels=1, base_filters=64, p=0.1):\n        super().__init__()\n        self.enc1 = DoubleConv2D(in_channels, base_filters, p)\n        self.enc2 = DoubleConv2D(base_filters, base_filters*2, p)\n        self.enc3 = DoubleConv2D(base_filters*2, base_filters*4, p)\n        self.pool = nn.MaxPool2d(2)\n        self.bottom = DoubleConv2D(base_filters*4, base_filters*8, p)\n        self.up2 = nn.ConvTranspose2d(base_filters*8, base_filters*4, 2, stride=2)\n        self.dec2 = DoubleConv2D(base_filters*8, base_filters*4, p)\n        self.up1 = nn.ConvTranspose2d(base_filters*4, base_filters*2, 2, stride=2)\n        self.dec1 = DoubleConv2D(base_filters*4, base_filters*2, p)\n        self.up0 = nn.ConvTranspose2d(base_filters*2, base_filters, 2, stride=2)\n        self.dec0 = DoubleConv2D(base_filters*2, base_filters, p)\n        self.out_conv = nn.Conv2d(base_filters, out_channels, 1)\n\n    def forward(self, x):\n        e1 = self.enc1(x)\n        e2 = self.enc2(self.pool(e1))\n        e3 = self.enc3(self.pool(e2))\n        b = self.bottom(self.pool(e3))\n        d2 = self.dec2(torch.cat([self.up2(b), e3], dim=1))\n        d1 = self.dec1(torch.cat([self.up1(d2), e2], dim=1))\n        d0 = self.dec0(torch.cat([self.up0(d1), e1], dim=1))\n        return torch.sigmoid(self.out_conv(d0))\n\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n\n\n# === Rutas necesarias ===\nimage_root = \"/kaggle/input/dataset-2d/New-UNet2D/img_2D/img_train\"\nmask_root = \"/kaggle/input/dataset-2d/New-UNet2D/mask_2D/mask_train\"\n\n# === Cargar dataset y modelo ===\ndataset = MyoSegDataset2D(image_root, mask_root)\npatient_ids = np.array(dataset.patients)\nlogo = LeaveOneGroupOut()\n\n# Identificar Ã­ndices de train/val para fold 5\nFOLD_ID = 4  # Fold 5 â†’ Ã­ndice 4 (Python index starts at 0)\nsplits = list(logo.split(np.arange(len(dataset)), groups=patient_ids))\ntrain_idx, val_idx = splits[FOLD_ID]\n\n# Crear loader de entrenamiento\ntrain_subset = Subset(dataset, train_idx)\ntrain_loader = DataLoader(train_subset, batch_size=1, shuffle=False)\n\n# Cargar modelo\nmodel = UNet2D().to(device)\nmodel.load_state_dict(torch.load(\"/kaggle/input/checkpoint/unet2d_best_fold5.pth\"))\nmodel.eval()\n\n# Crear carpeta para guardar predicciones si quieres\nos.makedirs(\"predicciones_train_fold5\", exist_ok=True)\n\n# === Inferencia sobre pacientes de entrenamiento ===\nwith torch.no_grad():\n    for i, (img, mask, path, patient_id) in tqdm(enumerate(train_loader), total=len(train_loader)):\n        img, mask = img.to(device), mask.to(device)\n        pred = model(img)\n        pred_bin = (pred > 0.5).float()\n\n        # VisualizaciÃ³n rÃ¡pida\n        pred_np = pred.squeeze().cpu().numpy()\n        overlay = np.clip(img.squeeze().cpu().numpy() + pred_np, 0, 1)\n\n        fig, axs = plt.subplots(1, 3, figsize=(12, 4))\n        axs[0].imshow(img.squeeze().cpu(), cmap=\"gray\"); axs[0].set_title(\"Imagen\")\n        axs[1].imshow(mask.squeeze().cpu(), cmap=\"gray\"); axs[1].set_title(\"MÃ¡scara GT\")\n        axs[2].imshow(overlay, cmap=\"hot\"); axs[2].set_title(\"PredicciÃ³n\")\n        for ax in axs: ax.axis(\"off\")\n        plt.tight_layout()\n        plt.savefig(f\"predicciones_train_fold5/pred_{i:03d}.png\")\n        plt.close()\n\nfrom torch.utils.data import Subset","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#PredicciÃ³n del paciente de validaciÃ³n para cada fold en cada caso\n\nimport os\nimport torch\nimport numpy as np\nfrom PIL import Image\nfrom tqdm import tqdm\nfrom torch.utils.data import Subset, DataLoader\nfrom torchvision import transforms\nfrom sklearn.model_selection import LeaveOneGroupOut\n\n# === Dataset personalizado\nclass MyoSegDataset2D(torch.utils.data.Dataset):\n    def __init__(self, image_root, mask_root):\n        self.image_paths, self.mask_paths, self.patients = [], [], []\n        for patient in sorted(os.listdir(image_root)):\n            img_folder = os.path.join(image_root, patient)\n            mask_folder = os.path.join(mask_root, patient)\n            if not os.path.isdir(mask_folder):\n                continue\n            imgs = sorted([f for f in os.listdir(img_folder) if f.endswith('.png')])\n            masks = sorted([f for f in os.listdir(mask_folder) if f.endswith('.png')])\n            for i, m in zip(imgs, masks):\n                self.image_paths.append(os.path.join(img_folder, i))\n                self.mask_paths.append(os.path.join(mask_folder, m))\n                self.patients.append(patient)\n        self.transform = transforms.ToTensor()\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        img = Image.open(self.image_paths[idx]).convert(\"L\")\n        mask = Image.open(self.mask_paths[idx]).convert(\"L\")\n        img = self.transform(img)\n        mask = (self.transform(mask) > 0).float()\n        return img, mask, self.image_paths[idx], self.patients[idx]\n\n# === UNet2D con Dropout y BatchNorm\nclass DoubleConv2D(torch.nn.Module):\n    def __init__(self, in_ch, out_ch, p=0.1):\n        super().__init__()\n        self.conv = torch.nn.Sequential(\n            torch.nn.Conv2d(in_ch, out_ch, 3, padding=1),\n            torch.nn.BatchNorm2d(out_ch),\n            torch.nn.ReLU(inplace=True),\n            torch.nn.Conv2d(out_ch, out_ch, 3, padding=1),\n            torch.nn.BatchNorm2d(out_ch),\n            torch.nn.ReLU(inplace=True),\n            torch.nn.Dropout2d(p)\n        )\n\n    def forward(self, x):\n        return self.conv(x)\n\nclass UNet2D(torch.nn.Module):\n    def __init__(self, in_channels=1, out_channels=1, base_filters=64, p=0.1):\n        super().__init__()\n        self.enc1 = DoubleConv2D(in_channels, base_filters, p)\n        self.enc2 = DoubleConv2D(base_filters, base_filters*2, p)\n        self.enc3 = DoubleConv2D(base_filters*2, base_filters*4, p)\n        self.pool = torch.nn.MaxPool2d(2)\n        self.bottom = DoubleConv2D(base_filters*4, base_filters*8, p)\n        self.up2 = torch.nn.ConvTranspose2d(base_filters*8, base_filters*4, 2, stride=2)\n        self.dec2 = DoubleConv2D(base_filters*8, base_filters*4, p)\n        self.up1 = torch.nn.ConvTranspose2d(base_filters*4, base_filters*2, 2, stride=2)\n        self.dec1 = DoubleConv2D(base_filters*4, base_filters*2, p)\n        self.up0 = torch.nn.ConvTranspose2d(base_filters*2, base_filters, 2, stride=2)\n        self.dec0 = DoubleConv2D(base_filters*2, base_filters, p)\n        self.out_conv = torch.nn.Conv2d(base_filters, out_channels, 1)\n\n    def forward(self, x):\n        e1 = self.enc1(x)\n        e2 = self.enc2(self.pool(e1))\n        e3 = self.enc3(self.pool(e2))\n        b = self.bottom(self.pool(e3))\n        d2 = self.dec2(torch.cat([self.up2(b), e3], dim=1))\n        d1 = self.dec1(torch.cat([self.up1(d2), e2], dim=1))\n        d0 = self.dec0(torch.cat([self.up0(d1), e1], dim=1))\n        return torch.sigmoid(self.out_conv(d0))\n\n# === CONFIGURACIÃ“N\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nimage_root = \"/kaggle/input/dataset-2d/New-UNet2D/img_2D/img_train\"\nmask_root = \"/kaggle/input/dataset-2d/New-UNet2D/mask_2D/mask_train\"\nmodel_dir = \"/kaggle/input/predicciones\"  # donde estÃ¡n los .pth del fold1 al 4\n\n# === Dataset y particiÃ³n Leave-One-Group-Out\ndataset = MyoSegDataset2D(image_root, mask_root)\npatient_ids = np.array(dataset.patients)\nlogo = LeaveOneGroupOut()\nsplits = list(logo.split(np.arange(len(dataset)), groups=patient_ids))\n\n# === Inference para folds 1 a 6\nfor fold_id in range(6):  # folds 0 a 5 â†’ Fold1 a Fold6\n    print(f\"\\nğŸ”„ Iniciando predicciÃ³n para Fold {fold_id + 1}\")\n    \n    _, val_idx = splits[fold_id]\n    val_loader = DataLoader(Subset(dataset, val_idx), batch_size=1, shuffle=False)\n\n    # Cargar modelo correspondiente\n    model = UNet2D().to(device)\n    model_path = os.path.join(model_dir, f\"unet2d_best_fold{fold_id + 1}.pth\")\n    model.load_state_dict(torch.load(model_path, map_location=device))\n    model.eval()\n\n    # Crear carpeta para guardar predicciones\n    pred_dir = f\"predicciones_fold{fold_id + 1}_val\"\n    os.makedirs(pred_dir, exist_ok=True)\n\n    with torch.no_grad():\n        for img, _, path, patient_id in tqdm(val_loader, desc=f\"Inferencia Fold {fold_id + 1}\"):\n            img = img.to(device)\n            pred = model(img)\n            pred_bin = (pred > 0.5).float().squeeze().cpu().numpy() * 255\n\n            fname = os.path.basename(path[0])\n            patient = patient_id[0]\n            out_folder = os.path.join(pred_dir, patient)\n            os.makedirs(out_folder, exist_ok=True)\n            Image.fromarray(pred_bin.astype(np.uint8)).save(os.path.join(out_folder, fname))\n\n    print(f\"âœ… Â¡Predicciones del fold {fold_id + 1} guardadas en: {pred_dir}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import shutil\n\n# Crear ZIP para cada carpeta de predicciones de fold\nfor fold_id in range(1, 7):  # folds 1 al 6\n    folder = f\"predicciones_fold{fold_id}_val\"\n    zip_name = f\"{folder}.zip\"\n    shutil.make_archive(folder, 'zip', folder)\n    print(f\"âœ… Carpeta '{folder}' comprimida como '{zip_name}'\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}